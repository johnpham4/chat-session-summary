Here is the full content of the **Vulcan Labs - AI Engineer Intern - Take-Home Test** documentation in English, as requested:

# **Chat Assistant with Session Memory**

### **Goal**
The objective is to build a working demo of a **chat assistant backend** (using a terminal, Streamlit, or Gradio) that supports two main features:
1.  **Session (short-term) memory** implemented via **automatic summarization** when the conversation context exceeds a configurable limit.
2.  **Query understanding and refinement**, which includes rewriting ambiguous queries, augmenting queries with relevant session memory, and generating clarifying questions when intent is unclear.

### **Evaluation Criteria**
The project will be evaluated based on:
*   **Clear pipeline design** (chat input → session memory → query understanding → final prompt construction).
*   **Stable, structured outputs** using a schema-first approach.
*   **Clear code organization**, documentation, and included test data.

### **Duration & Tools**
*   **Duration:** 7 days.
*   **Implementation:** Must be written in **Python**.
*   **Allowed Tools:** Any LLM/API (OpenAI, Claude, Gemini, etc.) and any framework (LangChain, LangGraph, etc.) or no framework at all.

### **Deliverables (Must Have)**
1.  **Runnable Project:** A functional backend demo (CLI/terminal is sufficient).
2.  **Documentation:** A **README.md** file with setup instructions, run guides, high-level design explanations, and limitations.
3.  **Structured Outputs:** Both session summarization and query understanding must follow **clearly defined schemas**.
4.  **Test Data:** At least **three conversation logs** (JSONL or text) demonstrating session memory triggers and ambiguous queries.

---

### **Functional Requirements**

#### **A. Session Memory via Summarization (Core)**
*   **Objective:** Automatically trigger summarization when the context exceeds a threshold (e.g., ~10k tokens).
*   **Trigger:** Use heuristic counting (words/characters) or tokenizer-based counting.
*   **Output:** A **structured session summary** including fields like `user_profile` (prefs/constraints), `key_facts`, `decisions`, `open_questions`, and `todos`.
*   **Storage:** The summary must be stored as short-term memory using the file system or a database.

#### **B. Query Understanding Pipeline (Core)**
When a new query is received, the system follows these steps:
*   **Step 1 — Rewrite / Paraphrase:** Detect if the query is ambiguous. If it is, rewrite it and output `is_ambiguous: true`.
*   **Step 2 — Context Augmentation:** Build context by combining the **N most recent messages** and relevant fields from the **session memory**.
*   **Step 3 — Clarifying Questions:** If the query remains unclear after rewriting, generate **1–3 clarifying questions** for the user.

---

### **Demo Requirements**
The demo must showcase two specific flows:
*   **Flow 1 — Session Memory Trigger:** Load a long log, show the context size increasing, and demonstrate the summarization being triggered and logged.
*   **Flow 2 — Ambiguous Query Handling:** Run an ambiguous query to show the process of **rewriting**, **augmentation**, and **clarifying questions**.

### **Scoring Rubric (10 Points Total)**
*   **Core features work end-to-end:** 0–6 points.
*   **Structured outputs & basic validation:** 0–1 point.
*   **Code structure & readability:** 0–2 points.
*   **Documentation & included test data:** 0–1 point.